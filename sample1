import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from scipy import stats

# Load data
df = pd.read_csv('your_data.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])

## Feature Engineering =======================================================

# Create time period categories first as strings
df['day_part'] = pd.cut(df['timestamp'].dt.hour,
                       bins=[0, 6, 12, 18, 24],
                       labels=['night', 'morning', 'afternoon', 'evening'],
                       right=False).astype(str)  # Convert to string immediately

# Calculate time period statistics (using string categories)
time_period_stats = df.groupby('day_part')['no_of_txns'].agg(['mean', 'std'])

# Map expected values to dataframe (using string categories)
df['expected_mean'] = df['day_part'].map(time_period_stats['mean'])
df['expected_std'] = df['day_part'].map(time_period_stats['std'])

# Handle cases where std=0 to avoid division by zero
df['expected_std'] = df['expected_std'].replace(0, 1)  # If no variation, assume std=1

# Now calculate z-scores safely
df['z_score'] = (df['no_of_txns'] - df['expected_mean']) / df['expected_std']

# Additional features
df['hour'] = df['timestamp'].dt.hour
df['minute_of_day'] = df['timestamp'].dt.hour * 60 + df['timestamp'].dt.minute
df['is_weekend'] = df['timestamp'].dt.dayofweek.isin([5, 6]).astype(int)
df['pct_of_expected'] = df['no_of_txns'] / df['expected_mean']

## Prepare Features =========================================================

numeric_features = ['minute_of_day', 'no_of_txns', 'z_score', 'pct_of_expected', 'hour']
categorical_features = ['day_part']

preprocessor = ColumnTransformer([
    ('num', RobustScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])

## Model Training ===========================================================

model = Pipeline([
    ('preprocessor', preprocessor),
    ('detector', IsolationForest(
        n_estimators=300,
        contamination='auto',
        random_state=42,
        verbose=1,
        max_features=0.8
    ))
])

model.fit(df)

## Predictions ==============================================================

df['anomaly_score'] = model.decision_function(df)
df['anomaly'] = model.predict(df)

# Post-processing to catch extreme values
high_threshold = df.groupby('day_part')['no_of_txns'].transform(lambda x: x.quantile(0.99))
low_threshold = df.groupby('day_part')['no_of_txns'].transform(lambda x: x.quantile(0.01))
df.loc[(df['no_of_txns'] > high_threshold) | (df['no_of_txns'] < low_threshold), 'anomaly'] = -1

## Analysis =================================================================

anomalies = df[df['anomaly'] == -1]
print(f"Detected {len(anomalies)} anomalies:")
print(anomalies.sort_values('anomaly_score')[['timestamp', 'no_of_txns', 'day_part', 'anomaly_score']])

## Visualization ============================================================

plt.figure(figsize=(18, 8))

# Plot 1: Transactions by time of day
plt.subplot(1, 2, 1)
for day_part in df['day_part'].unique():
    subset = df[df['day_part'] == day_part]
    plt.scatter(subset['minute_of_day'], subset['no_of_txns'], 
               alpha=0.5, label=day_part)
plt.scatter(anomalies['minute_of_day'], anomalies['no_of_txns'],
           c='red', s=100, edgecolor='black', label='Anomaly')
plt.title("Transactions by Time of Day")
plt.xlabel("Minute of Day")
plt.ylabel("Transaction Count")
plt.legend()

# Plot 2: Z-score distribution
plt.subplot(1, 2, 2)
plt.hist(df['z_score'], bins=50, alpha=0.7, label='All')
plt.hist(anomalies['z_score'], bins=50, alpha=0.7, color='red', label='Anomalies')
plt.axvline(-3, color='black', linestyle='--')
plt.axvline(3, color='black', linestyle='--')
plt.title("Z-score Distribution")
plt.xlabel("Z-score")
plt.ylabel("Frequency")
plt.legend()

plt.tight_layout()
plt.show()

# Save results
df.to_csv('time_aware_anomaly_results.csv', index=False)
